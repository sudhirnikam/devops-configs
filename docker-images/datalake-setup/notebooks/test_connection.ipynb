{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a00e4d-844c-4e87-a394-e2f355d360ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Spark Session...\n",
      "======================================================================\n",
      "‚úÖ Spark Session created successfully!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "SPARK CLUSTER INFORMATION\n",
      "======================================================================\n",
      "Spark Version: 3.5.0\n",
      "Master URL: spark://spark-master:7077\n",
      "Application Name: DataLake - Medallion Architecture\n",
      "Application ID: app-20251123110925-0000\n",
      "Default Parallelism: 2\n",
      "Spark UI: http://localhost:4040\n",
      "Master UI: http://localhost:8080\n",
      "\n",
      "üìä Cluster Status:\n",
      "‚úÖ Connected to Standalone Cluster\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 1: DISTRIBUTED PROCESSING\n",
      "======================================================================\n",
      "Created RDD with 1000 elements\n",
      "Number of partitions: 6\n",
      "First partition sample: [1, 2, 3, 4, 5]\n",
      "Sum of doubled values: 1001000\n",
      "‚úÖ Distributed processing working!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 2: MINIO CONNECTION - WRITE DATA\n",
      "======================================================================\n",
      "Sample DataFrame:\n",
      "+---+-----+---+-----------+--------+\n",
      "| id| name|age| department|  salary|\n",
      "+---+-----+---+-----------+--------+\n",
      "|  1|Alice| 34|Engineering| 95000.5|\n",
      "|  2|  Bob| 45|      Sales| 78000.0|\n",
      "|  3|Cathy| 29|Engineering|88000.75|\n",
      "|  4|David| 52| Management|120000.0|\n",
      "|  5|  Eve| 38|      Sales|82000.25|\n",
      "+---+-----+---+-----------+--------+\n",
      "\n",
      "\n",
      "üìù Writing to MinIO: s3a://bronze/test_employees/\n",
      "‚úÖ Successfully wrote data to MinIO Bronze layer!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 3: MINIO CONNECTION - READ DATA\n",
      "======================================================================\n",
      "üìñ Reading from MinIO: s3a://bronze/test_employees/\n",
      "‚úÖ Successfully read 5 records from MinIO!\n",
      "\n",
      "Data from MinIO:\n",
      "+---+-----+---+-----------+--------+\n",
      "| id| name|age| department|  salary|\n",
      "+---+-----+---+-----------+--------+\n",
      "|  1|Alice| 34|Engineering| 95000.5|\n",
      "|  2|  Bob| 45|      Sales| 78000.0|\n",
      "|  3|Cathy| 29|Engineering|88000.75|\n",
      "|  4|David| 52| Management|120000.0|\n",
      "|  5|  Eve| 38|      Sales|82000.25|\n",
      "+---+-----+---+-----------+--------+\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 4: POSTGRESQL CONNECTION - WRITE DATA\n",
      "======================================================================\n",
      "üìù Writing to PostgreSQL table: employees\n",
      "‚úÖ Successfully wrote data to PostgreSQL!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 5: POSTGRESQL CONNECTION - READ DATA\n",
      "======================================================================\n",
      "üìñ Reading from PostgreSQL table: employees\n",
      "‚úÖ Successfully read 5 records from PostgreSQL!\n",
      "\n",
      "Data from PostgreSQL:\n",
      "+---+-----+---+-----------+--------+--------------------------+\n",
      "|id |name |age|department |salary  |created_at                |\n",
      "+---+-----+---+-----------+--------+--------------------------+\n",
      "|4  |David|52 |Management |120000.0|2025-11-23 11:10:25.734597|\n",
      "|5  |Eve  |38 |Sales      |82000.25|2025-11-23 11:10:25.734597|\n",
      "|2  |Bob  |45 |Sales      |78000.0 |2025-11-23 11:10:25.734597|\n",
      "|3  |Cathy|29 |Engineering|88000.75|2025-11-23 11:10:25.734597|\n",
      "|1  |Alice|34 |Engineering|95000.5 |2025-11-23 11:10:25.734597|\n",
      "+---+-----+---+-----------+--------+--------------------------+\n",
      "\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 6: COMPLETE MEDALLION PIPELINE\n",
      "======================================================================\n",
      "\n",
      "ü•â BRONZE LAYER - Raw Data\n",
      "Records: 5\n",
      "+---+-----+---+-----------+--------+\n",
      "| id| name|age| department|  salary|\n",
      "+---+-----+---+-----------+--------+\n",
      "|  1|Alice| 34|Engineering| 95000.5|\n",
      "|  2|  Bob| 45|      Sales| 78000.0|\n",
      "|  3|Cathy| 29|Engineering|88000.75|\n",
      "|  4|David| 52| Management|120000.0|\n",
      "|  5|  Eve| 38|      Sales|82000.25|\n",
      "+---+-----+---+-----------+--------+\n",
      "\n",
      "\n",
      "ü•à SILVER LAYER - Cleaned & Transformed Data\n",
      "‚úÖ Wrote to Silver layer: s3a://silver/test_employees/\n",
      "Records: 4\n",
      "+---+-----+---+-----------+--------+------------+--------------------+\n",
      "| id| name|age| department|  salary|salary_grade| processed_timestamp|\n",
      "+---+-----+---+-----------+--------+------------+--------------------+\n",
      "|  1|Alice| 34|Engineering| 95000.5|      Medium|2025-11-23 11:10:...|\n",
      "|  2|  Bob| 45|      Sales| 78000.0|         Low|2025-11-23 11:10:...|\n",
      "|  4|David| 52| Management|120000.0|        High|2025-11-23 11:10:...|\n",
      "|  5|  Eve| 38|      Sales|82000.25|      Medium|2025-11-23 11:10:...|\n",
      "+---+-----+---+-----------+--------+------------+--------------------+\n",
      "\n",
      "\n",
      "ü•á GOLD LAYER - Business Aggregations\n",
      "‚úÖ Wrote to Gold layer: s3a://gold/test_employees_summary/\n",
      "Records: 4\n",
      "+-----------+------------+--------------+----------+-------+-------+\n",
      "| department|salary_grade|employee_count|avg_salary|min_age|max_age|\n",
      "+-----------+------------+--------------+----------+-------+-------+\n",
      "|Engineering|      Medium|             1|   95000.5|     34|     34|\n",
      "| Management|        High|             1|  120000.0|     52|     52|\n",
      "|      Sales|         Low|             1|   78000.0|     45|     45|\n",
      "|      Sales|      Medium|             1|  82000.25|     38|     38|\n",
      "+-----------+------------+--------------+----------+-------+-------+\n",
      "\n",
      "‚úÖ Wrote Gold layer to PostgreSQL table: employees_summary\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üéâ CONNECTION TEST SUMMARY\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Spark Standalone Cluster - Connected\n",
      "‚úÖ MinIO (S3) - Read/Write Working\n",
      "‚úÖ PostgreSQL - Read/Write Working\n",
      "‚úÖ Medallion Pipeline - Functional\n",
      "\n",
      "üìä Data Locations:\n",
      "   Bronze: s3a://bronze/test_employees/\n",
      "   Silver: s3a://silver/test_employees/\n",
      "   Gold:   s3a://gold/test_employees_summary/\n",
      "   \n",
      "üíæ PostgreSQL Tables:\n",
      "   - employees\n",
      "   - employees_summary (for Metabase)\n",
      "\n",
      "üåê Access Points:\n",
      "   - Spark UI: http://localhost:4040\n",
      "   - Master UI: http://localhost:8080\n",
      "   - MinIO Console: http://localhost:9001\n",
      "   - JupyterLab: http://localhost:8888\n",
      "   - Metabase: http://localhost:3000\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SPARK SESSION CONFIGURATION - Connect to Cluster, MinIO, and PostgreSQL\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "\n",
    "print(\"Creating Spark Session...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create Spark Session with all configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataLake - Medallion Architecture\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.cores.max\", \"3\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4,\"\n",
    "            \"com.amazonaws:aws-java-sdk-bundle:1.12.262,\"\n",
    "            \"org.postgresql:postgresql:42.5.4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to reduce noise\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"‚úÖ Spark Session created successfully!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFY CLUSTER CONNECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SPARK CLUSTER INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Master URL: {sc.master}\")\n",
    "print(f\"Application Name: {sc.appName}\")\n",
    "print(f\"Application ID: {sc.applicationId}\")\n",
    "print(f\"Default Parallelism: {sc.defaultParallelism}\")\n",
    "print(f\"Spark UI: http://localhost:4040\")\n",
    "print(f\"Master UI: http://localhost:8080\")\n",
    "\n",
    "print(\"\\nüìä Cluster Status:\")\n",
    "if sc.master.startswith(\"spark://\"):\n",
    "    print(\"‚úÖ Connected to Standalone Cluster\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Running in Local Mode\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 1: VERIFY DISTRIBUTED PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 1: DISTRIBUTED PROCESSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create test data distributed across workers\n",
    "data = list(range(1, 1001))\n",
    "rdd = sc.parallelize(data, 6)  # 6 partitions for 3 workers\n",
    "\n",
    "print(f\"Created RDD with {rdd.count()} elements\")\n",
    "print(f\"Number of partitions: {rdd.getNumPartitions()}\")\n",
    "print(f\"First partition sample: {rdd.glom().collect()[0][:5]}\")\n",
    "\n",
    "# Simple computation\n",
    "result = rdd.map(lambda x: x * 2).sum()\n",
    "print(f\"Sum of doubled values: {result}\")\n",
    "print(\"‚úÖ Distributed processing working!\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 2: MINIO (S3) CONNECTION - WRITE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 2: MINIO CONNECTION - WRITE DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create sample DataFrame\n",
    "sample_data = [\n",
    "    (1, \"Alice\", 34, \"Engineering\", 95000.50),\n",
    "    (2, \"Bob\", 45, \"Sales\", 78000.00),\n",
    "    (3, \"Cathy\", 29, \"Engineering\", 88000.75),\n",
    "    (4, \"David\", 52, \"Management\", 120000.00),\n",
    "    (5, \"Eve\", 38, \"Sales\", 82000.25)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"age\", IntegerType(), False),\n",
    "    StructField(\"department\", StringType(), False),\n",
    "    StructField(\"salary\", DoubleType(), False)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(sample_data, schema)\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "df.show()\n",
    "\n",
    "# Write to MinIO Bronze layer\n",
    "bronze_path = \"s3a://bronze/test_employees/\"\n",
    "print(f\"\\nüìù Writing to MinIO: {bronze_path}\")\n",
    "\n",
    "try:\n",
    "    df.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(bronze_path)\n",
    "    print(\"‚úÖ Successfully wrote data to MinIO Bronze layer!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error writing to MinIO: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 3: MINIO (S3) CONNECTION - READ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 3: MINIO CONNECTION - READ DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"üìñ Reading from MinIO: {bronze_path}\")\n",
    "\n",
    "try:\n",
    "    df_read = spark.read.parquet(bronze_path)\n",
    "    print(f\"‚úÖ Successfully read {df_read.count()} records from MinIO!\")\n",
    "    print(\"\\nData from MinIO:\")\n",
    "    df_read.show()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading from MinIO: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 4: POSTGRESQL CONNECTION - WRITE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 4: POSTGRESQL CONNECTION - WRITE DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Add timestamp column\n",
    "df_with_timestamp = df.withColumn(\"created_at\", current_timestamp())\n",
    "\n",
    "# PostgreSQL connection properties\n",
    "postgres_url = \"jdbc:postgresql://postgres:5432/gold_db\"\n",
    "postgres_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "table_name = \"employees\"\n",
    "\n",
    "print(f\"üìù Writing to PostgreSQL table: {table_name}\")\n",
    "\n",
    "try:\n",
    "    df_with_timestamp.write \\\n",
    "        .jdbc(url=postgres_url, \n",
    "              table=table_name, \n",
    "              mode=\"overwrite\", \n",
    "              properties=postgres_properties)\n",
    "    print(\"‚úÖ Successfully wrote data to PostgreSQL!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error writing to PostgreSQL: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 5: POSTGRESQL CONNECTION - READ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 5: POSTGRESQL CONNECTION - READ DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"üìñ Reading from PostgreSQL table: {table_name}\")\n",
    "\n",
    "try:\n",
    "    df_postgres = spark.read \\\n",
    "        .jdbc(url=postgres_url, \n",
    "              table=table_name, \n",
    "              properties=postgres_properties)\n",
    "    \n",
    "    print(f\"‚úÖ Successfully read {df_postgres.count()} records from PostgreSQL!\")\n",
    "    print(\"\\nData from PostgreSQL:\")\n",
    "    df_postgres.show(truncate=False)\n",
    "    \n",
    "    print(\"\\nSchema:\")\n",
    "    df_postgres.printSchema()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading from PostgreSQL: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 6: COMPLETE PIPELINE - Bronze ‚Üí Silver ‚Üí Gold\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 6: COMPLETE MEDALLION PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# BRONZE: Raw data (already written above)\n",
    "print(\"\\nü•â BRONZE LAYER - Raw Data\")\n",
    "bronze_df = spark.read.parquet(\"s3a://bronze/test_employees/\")\n",
    "print(f\"Records: {bronze_df.count()}\")\n",
    "bronze_df.show(5)\n",
    "\n",
    "# SILVER: Clean and transform\n",
    "print(\"\\nü•à SILVER LAYER - Cleaned & Transformed Data\")\n",
    "silver_df = bronze_df \\\n",
    "    .filter(col(\"age\") >= 30) \\\n",
    "    .withColumn(\"salary_grade\", \n",
    "                when(col(\"salary\") >= 100000, \"High\")\n",
    "                .when(col(\"salary\") >= 80000, \"Medium\")\n",
    "                .otherwise(\"Low\")) \\\n",
    "    .withColumn(\"processed_timestamp\", current_timestamp())\n",
    "\n",
    "silver_path = \"s3a://silver/test_employees/\"\n",
    "silver_df.write.mode(\"overwrite\").parquet(silver_path)\n",
    "print(f\"‚úÖ Wrote to Silver layer: {silver_path}\")\n",
    "print(f\"Records: {silver_df.count()}\")\n",
    "silver_df.show()\n",
    "\n",
    "# GOLD: Aggregated business metrics\n",
    "print(\"\\nü•á GOLD LAYER - Business Aggregations\")\n",
    "gold_df = silver_df.groupBy(\"department\", \"salary_grade\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"employee_count\"),\n",
    "        avg(\"salary\").alias(\"avg_salary\"),\n",
    "        min(\"age\").alias(\"min_age\"),\n",
    "        max(\"age\").alias(\"max_age\")\n",
    "    ) \\\n",
    "    .orderBy(\"department\", \"salary_grade\")\n",
    "\n",
    "gold_path = \"s3a://gold/test_employees_summary/\"\n",
    "gold_df.write.mode(\"overwrite\").parquet(gold_path)\n",
    "print(f\"‚úÖ Wrote to Gold layer: {gold_path}\")\n",
    "print(f\"Records: {gold_df.count()}\")\n",
    "gold_df.show()\n",
    "\n",
    "# Write Gold layer to PostgreSQL for Metabase\n",
    "gold_table = \"employees_summary\"\n",
    "gold_df.write \\\n",
    "    .jdbc(url=postgres_url, \n",
    "          table=gold_table, \n",
    "          mode=\"overwrite\", \n",
    "          properties=postgres_properties)\n",
    "print(f\"‚úÖ Wrote Gold layer to PostgreSQL table: {gold_table}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ CONNECTION TEST SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = \"\"\"\n",
    "‚úÖ Spark Standalone Cluster - Connected\n",
    "‚úÖ MinIO (S3) - Read/Write Working\n",
    "‚úÖ PostgreSQL - Read/Write Working\n",
    "‚úÖ Medallion Pipeline - Functional\n",
    "\n",
    "üìä Data Locations:\n",
    "   Bronze: s3a://bronze/test_employees/\n",
    "   Silver: s3a://silver/test_employees/\n",
    "   Gold:   s3a://gold/test_employees_summary/\n",
    "   \n",
    "üíæ PostgreSQL Tables:\n",
    "   - employees\n",
    "   - employees_summary (for Metabase)\n",
    "\n",
    "üåê Access Points:\n",
    "   - Spark UI: http://localhost:4040\n",
    "   - Master UI: http://localhost:8080\n",
    "   - MinIO Console: http://localhost:9001\n",
    "   - JupyterLab: http://localhost:8888\n",
    "   - Metabase: http://localhost:3000\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e2c4b70-4d00-4705-a43d-dc37c5f60646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(f\"PySpark version: {pyspark.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
